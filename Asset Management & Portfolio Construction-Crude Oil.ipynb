{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project \n",
    "##  - Asset Management & Portfolio Construction\n",
    "\n",
    "Group Members: \n",
    "Yuchen Wang & Chengyi Xu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Overview\n",
    "- Essential Libraries\n",
    "- Data\n",
    "- Exploratory Data Analysis\n",
    "    - Remove unrelated companies\n",
    "    - Find and remove irregular entries\n",
    "    - Seperate the dataframe by ticker\n",
    "    - Combine the same company with different ticker\n",
    "    - Readjust the datapool\n",
    "- Calculation of important data\n",
    "- Portfolio Creation\n",
    "- Plot the efficient frontier\n",
    "- Portfolio Analysis\n",
    "- Next Steps: Portfolio prediction testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Crude oil has been viewed as the single most important commodity in the world for its unreplaceable role in modern manufacturing industries. As a nonrenewable natural resource, crude oil is scarce in both economic and everyday definitions, so its price is expected to fluctuate with supply and demand on the market. Investors for businesses in the crude oil production industries see this fluctuation as both opportunities and potential risks. There is great interest in studying how to build a portfolio with smaller volatility but higher return. \n",
    "We take 10 publicly traded crude oil producers as our stock pool in our study. They are: \n",
    "- Occidental Petroleum (OXY)\n",
    "- Continental Resources (CLR)\n",
    "- Marathon Oil (MRO)\n",
    "- EOG Resources (EOG)\n",
    "- ConocoPhilips (COP)\n",
    "- Diamondback Energy (FANG)\n",
    "- Exxon Mobil Corporation (XOM)\n",
    "- Chevron Corporation (CVX)\n",
    "- Ovintiv Inc. (OVV)\n",
    "- Pioneer Natural Resources Corporation (PXD)\n",
    "\n",
    "We take the S&P500, Dow Jones Industrial Average, and Crude oil Nov 22 as the benchmarks to represent the market turbulence. \n",
    "To test the reliability of our rebalancing strategy, we will test out with out-of-sample data by using the “future” data from the set date of our study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The crude oil industry is a mature market, and the companies in the industry have a long enough history for us to test our models. The industry itself experiences a lot of turbulence, and the thriving times and the depressed times appeared interchangeably, the pattern shown in the industry making it suitable for time series analysis. Shale oil, benefited from technology advancement, has a great potential in future production growth. The companies chosen are the top 10 shale oil producers in 2020, and three indices are used as benchmark predictors.\n",
    "\n",
    "The data set is acquired mainly from three sources.\n",
    "1. Historical trading data of the companies from CRSP dataset by WRDS\n",
    "2. Historical financial reporting data of companies from Yahoo Finance Plus\n",
    "3. Historical values of Index data from CRSP dataset by WRDS\n",
    "\n",
    "We use historical daily data for seven top companies in the crude oil industry from 2002 to 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring risk-free rates from yahoo finance\n",
    "# here, 10-year T-bond is used for risk free rate\n",
    "\n",
    "import yfinance as yf\n",
    "t_bond_df = yf.download('^TNX', start = '1990-01-02', end = '2022-03-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bond_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bond_df = t_bond_df.reset_index()\n",
    "t_bond_df['TICKER'] = 'RF'\n",
    "t_bond_df['PRC'] = t_bond_df['Close']\n",
    "t_bond_df['COMNAM'] = \"Risk_free\"\n",
    "t_bond_df['date'] = pd.to_datetime(t_bond_df['Date']).dt.strftime('%Y%m%d')\n",
    "t_bond_df = t_bond_df[[\"TICKER\", \"PRC\",\"date\",\"COMNAM\"]]\n",
    "t_bond_df = t_bond_df.set_index(\"COMNAM\")\n",
    "t_bond_df['date'] = t_bond_df['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bond_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "oil_df = pd.read_csv('/Users/chengyixu/Desktop/JHU/fall 2 computional/final 2/oil_comp.csv', low_memory = False)\n",
    "#oil_df = pd.read_csv('F:\\\\Data_Learning\\\\computational_fin\\\\raw_data.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic summary\n",
    "oil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring market return rates from yahoo finance\n",
    "# here, S&P 500 is used for risk free rate\n",
    "SP500_df = yf.download('^GSPC', start = '1990-01-02', end = '2022-03-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Some of the companies changed their names and tickers due to operational changes and company mergers. The raw data pool combined them altogther. \n",
    "\n",
    "There are noise in the data needed to be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unrelated companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of the DataFrame to the stock name\n",
    "oil_with_index = oil_df.set_index(\"COMNAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_comp = [\n",
    "    \"COPLEY PROPERTY INC\",\n",
    "    \"CLARION COMMERCIAL HOLDINGS INC\",\n",
    "    \"COLOR SYSTEM TECHNOLOGY INC\",\n",
    "    \"C S T ENTERTAINMENT IMAGING INC\",\n",
    "    \"C S T ENTERTAINMENT INC\",\n",
    "    \"CONSOLIDATED PRODUCTS INC\",\n",
    "    \"STEAK N SHAKE CO\",\n",
    "    \"BIGLARI HOLDINGS INC\"\n",
    "]\n",
    "\n",
    "oil_with_index = oil_with_index.drop(other_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unrelated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing the unuseful columns\n",
    "vis_col = ['date', 'TICKER', 'PRC', 'RET', 'VOL', 'BIDLO', 'ASKHI', 'RETX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index = oil_with_index[vis_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and remove irregular entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "def check_missing_values(df, df_name):\n",
    "  print(f'Number of missing Values by Feature in {df_name}\\n',df.isnull().sum())\n",
    "  columns_with_NaNs = []\n",
    "  dates_with_NaNs = []\n",
    "  for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "      null_series = df[col].isnull()\n",
    "      columns_with_NaNs.append(col)\n",
    "      dates_with_NaNs.append(null_series[null_series].index)\n",
    "  print('Columns with NaNs:',columns_with_NaNs)\n",
    "  print('Columns with NaNs:',dates_with_NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_values(oil_with_index, 'oil_with_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index = oil_with_index[oil_with_index['RET'] != 'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate the dataframe by ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHV dataframe\n",
    "CHV_df = oil_with_index[oil_with_index['TICKER'] == 'CHV']\n",
    "#CLR dataframe\n",
    "CLR_df = oil_with_index[oil_with_index['TICKER'] == 'CLR']\n",
    "#COP dataframe\n",
    "COP_df = oil_with_index[oil_with_index['TICKER'] == 'COP']\n",
    "#COPI dataframe\n",
    "COPI_df = oil_with_index[oil_with_index['TICKER'] == 'COPI']\n",
    "#CVX dataframe\n",
    "CVX_df = oil_with_index[oil_with_index['TICKER'] == 'CVX']\n",
    "#ECA dataframe\n",
    "ECA_df = oil_with_index[oil_with_index['TICKER'] == 'ECA']\n",
    "#EOG dataframe\n",
    "EOG_df = oil_with_index[oil_with_index['TICKER'] == 'EOG']\n",
    "#FANG dataframe\n",
    "FANG_df = oil_with_index[oil_with_index['TICKER'] == 'FANG']\n",
    "#MRO dataframe\n",
    "MRO_df = oil_with_index[oil_with_index['TICKER'] == 'MRO']\n",
    "#OVV dataframe\n",
    "OVV_df = oil_with_index[oil_with_index['TICKER'] == 'OVV']\n",
    "#OXY dataframe\n",
    "OXY_df = oil_with_index[oil_with_index['TICKER'] == 'OXY']\n",
    "#P dataframe\n",
    "P_df = oil_with_index[oil_with_index['TICKER'] == 'P']\n",
    "#PCX dataframe\n",
    "PCX_df = oil_with_index[oil_with_index['TICKER'] == 'PCX']\n",
    "#PDP dataframe\n",
    "PDP_df = oil_with_index[oil_with_index['TICKER'] == 'PDP']\n",
    "#X dataframe\n",
    "X_df = oil_with_index[oil_with_index['TICKER'] == 'X']\n",
    "#XOM dataframe\n",
    "XOM_df = oil_with_index[oil_with_index['TICKER'] == 'XOM']\n",
    "#XON dataframe\n",
    "XON_df = oil_with_index[oil_with_index['TICKER'] == 'XON']\n",
    "#XON dataframe\n",
    "PXD_df = oil_with_index[oil_with_index['TICKER'] == 'PXD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index.groupby('TICKER')['date'].agg(['min','max']).sort_values(by=['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index.groupby('COMNAM')['date'].agg(['min','max']).sort_values(by=['min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the same company with different ticker\n",
    "We have observed that some of the companies changed their company names in the past, and changed their tickers at the same time. It does not make sense to see them as different companies. With the aggregated data grouped by company names and their tickers, we can combine them together so that it creates a continuous record under the same name and ticker. \n",
    "\n",
    "After the combination, log return is calculated at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet ticker\n",
    "XOM_united = pd.concat([XOM_df, XON_df], axis=0)\n",
    "XOM_united['TICKER'] = XOM_united['TICKER'].replace(['XON'], 'XOM')\n",
    "XOM_united.sort_values(by=['date'])\n",
    "XOM_united['RET'] = XOM_united['RET'].astype(float)\n",
    "XOM_united['logreturn'] = np.log(1+XOM_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet ticker\n",
    "PXD_united = pd.concat([PXD_df, PDP_df], axis=0)\n",
    "PXD_united['TICKER'] = PXD_united['TICKER'].replace(['PDP'], 'PXD')\n",
    "PXD_united.sort_values(by=['date'])\n",
    "PXD_united['RET'] = PXD_united['RET'].astype(float)\n",
    "PXD_united['logreturn'] = np.log(1+PXD_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet ticker\n",
    "CVX_united = pd.concat([CVX_df, CHV_df], axis=0)\n",
    "CVX_united['TICKER'] = CVX_united['TICKER'].replace(['CHV'], 'CVX')\n",
    "CVX_united.sort_values(by=['date'])\n",
    "CVX_united['RET'] = CVX_united['RET'].astype(float)\n",
    "CVX_united['logreturn'] = np.log(1+CVX_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet ticker\n",
    "MRO_united = pd.concat([MRO_df, X_df], axis=0)\n",
    "MRO_united['TICKER'] = MRO_united['TICKER'].replace(['X'], 'MRO')\n",
    "MRO_united.sort_values(by=['date'])\n",
    "MRO_united['RET'] = MRO_united['RET'].astype(float)\n",
    "MRO_united['logreturn'] = np.log(1+MRO_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet tickers\n",
    "OVV_united = pd.concat([OVV_df, PCX_df, ECA_df], axis=0)\n",
    "OVV_united['TICKER'] = OVV_united['TICKER'].replace(['PCX'], 'OVV')\n",
    "OVV_united['TICKER'] = OVV_united['TICKER'].replace(['ECA'], 'OVV')\n",
    "OVV_united.sort_values(by=['date'])\n",
    "OVV_united['RET'] = OVV_united['RET'].astype(float)\n",
    "OVV_united['logreturn'] = np.log(1+OVV_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same company with differnet tickers\n",
    "COP_united = pd.concat([COP_df, P_df], axis=0)\n",
    "COP_united['TICKER'] = COP_united['TICKER'].replace(['P'], 'COP')\n",
    "COP_united.sort_values(by=['date'])\n",
    "COP_united['RET'] = COP_united['RET'].astype(float)\n",
    "COP_united['logreturn'] = np.log(1+COP_united['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOG_df['RET'] = EOG_df['RET'].astype(float)\n",
    "EOG_df['logreturn'] = np.log(1+EOG_df['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OXY_df['RET'] = OXY_df['RET'].astype(float)\n",
    "OXY_df['logreturn'] = np.log(1+OXY_df['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FANG_df['RET'] = FANG_df['RET'].astype(float)\n",
    "FANG_df['logreturn'] = np.log(1+FANG_df['RET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLR_df['RET'] = CLR_df['RET'].astype(float)\n",
    "CLR_df['logreturn'] = np.log(1+CLR_df['RET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readjust the datapool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all data frames of each stock together.\n",
    "Oil_df_final = pd.concat([\n",
    "    COP_united, \n",
    "    PXD_united, \n",
    "    XOM_united, \n",
    "    CVX_united, \n",
    "    MRO_united, \n",
    "    EOG_df, \n",
    "    OXY_df, \n",
    "    FANG_df, \n",
    "    OVV_united, \n",
    "    CLR_df,\n",
    "    t_bond_df\n",
    "    ], axis=0)\n",
    "\n",
    "Oil_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oil_df_final.groupby('TICKER')['date'].agg(['min','max']).sort_values(by=['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design a function to select how many years to test\n",
    "def decided_period(n):\n",
    "    max_date = 20220331\n",
    "    decided_date = 20220331 - n*10000\n",
    "    return decided_date\n",
    "\n",
    "Oil_df_final_2 = Oil_df_final[(Oil_df_final['date'] >= decided_period(3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust the data\n",
    "SP500_df = SP500_df.reset_index()\n",
    "SP500_df['TICKER'] = 'MKT'\n",
    "SP500_df['PRC'] = SP500_df['Close']\n",
    "SP500_df['COMNAM'] = \"Market_Return\"\n",
    "SP500_df['date'] = pd.to_datetime(SP500_df['Date']).dt.strftime('%Y%m%d')\n",
    "SP500_df = SP500_df[[\"TICKER\", \"PRC\",\"date\",\"COMNAM\"]]\n",
    "SP500_df = SP500_df.set_index(\"COMNAM\")\n",
    "SP500_df['date'] = SP500_df['date'].astype(int)\n",
    "SP500_df_2 = SP500_df[(SP500_df['date'] > decided_period(3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the Market Return\n",
    "MKT = SP500_df_2[\"PRC\"].pct_change().apply(lambda x: np.log(1 + x)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep it clearer\n",
    "Oil_short = Oil_df_final_2[[\"TICKER\", \"PRC\",\"date\"]]\n",
    "Oil_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pivot table\n",
    "oil_table = Oil_short.pivot_table(index='date', columns='TICKER', values='PRC', aggfunc='sum').sort_values('date', ascending=True)\n",
    "oil_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of important data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct cov matrix, it is log metric here.\n",
    "cov_matrix = oil_table.pct_change().apply(lambda x: np.log(1+x)).cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr matrix, log here\n",
    "corr_matrix = oil_table.pct_change().apply(lambda x: np.log(1+x)).corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Betas\n",
    "betas = cov_matrix['RF'] / cov_matrix.loc['RF','RF']\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate period returns\n",
    "ind_er = oil_table.pct_change().apply(lambda x: np.log(1+x)).sum()\n",
    "ind_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find peiod std, need work\n",
    "ann_sd = oil_table.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(252*3))\n",
    "ann_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table for this.\n",
    "assets = pd.concat([ind_er, ann_sd], axis=1) # Creating a table for visualising returns and volatility of assets\n",
    "assets.columns = ['Returns', 'Volatility']\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index.iloc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_with_index.groupby('TICKER')['date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the portofilio\n",
    "\n",
    "p_ret = [] # Define an empty array for portfolio returns\n",
    "p_vol = [] # Define an empty array for portfolio volatility\n",
    "p_weights = [] # Define an empty array for asset weights\n",
    "\n",
    "num_assets = len(oil_table.columns)\n",
    "num_portfolios = 1000\n",
    "\n",
    "for portfolio in range(num_portfolios):\n",
    "    weights = []\n",
    "    for portfolio in range(num_portfolios):\n",
    "        weight = np.random.uniform(-3, 3, num_assets)\n",
    "        weight = weight/np.sum(weight)\n",
    "        if all(value < 3 and value > -3 for value in weight):\n",
    "            weights = weight\n",
    "    p_weights.append(weights)\n",
    "    returns = np.dot(weights, ind_er) # Returns are the product of individual expected returns of asset and its \n",
    "                                      # weights \n",
    "    p_ret.append(returns)\n",
    "    var = cov_matrix.mul(weights, axis=0).mul(weights, axis=1).sum().sum()# Portfolio Variance\n",
    "    sd = np.sqrt(var) # Daily standard deviation\n",
    "    ann_sd = sd*np.sqrt(252) # Annual standard deviation = volatility\n",
    "    p_vol.append(ann_sd)\n",
    "\n",
    "data = {'Returns':p_ret, 'Volatility':p_vol}\n",
    "\n",
    "for counter, symbol in enumerate(oil_table.columns.tolist()):\n",
    "    #print(counter, symbol)\n",
    "    data[symbol+' weight'] = [w[counter] for w in p_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the portofolio with more metrics\n",
    "portfolios  = pd.DataFrame(data)\n",
    "portfolios['Sharpe'] = (portfolios['Returns'] - ind_er.iloc[-2])/ portfolios['Volatility']\n",
    "\n",
    "portfolios['Treynor'] = (portfolios['Returns'] - ind_er.iloc[-2])/ (\n",
    "    portfolios['CLR weight'] * betas.iloc[0] +\n",
    "    portfolios['COP weight'] * betas.iloc[1] +\n",
    "    portfolios['CVX weight'] * betas.iloc[2] +\n",
    "    portfolios['EOG weight'] * betas.iloc[3] +\n",
    "    portfolios['FANG weight'] * betas.iloc[4] +\n",
    "    portfolios['MRO weight'] * betas.iloc[5] +\n",
    "    portfolios['OVV weight'] * betas.iloc[6] +\n",
    "    portfolios['OXY weight'] * betas.iloc[7] +\n",
    "    portfolios['PXD weight'] * betas.iloc[8] +\n",
    "    portfolios['RF weight'] * betas.iloc[9] +\n",
    "    portfolios['XOM weight'] * betas.iloc[-1])\n",
    "\n",
    "portfolios['Jensen'] = portfolios['Returns'] - ind_er.iloc[-2] - (\n",
    "    portfolios['CLR weight'] * betas.iloc[0] +\n",
    "    portfolios['COP weight'] * betas.iloc[1] +\n",
    "    portfolios['CVX weight'] * betas.iloc[2] +\n",
    "    portfolios['EOG weight'] * betas.iloc[3] +\n",
    "    portfolios['FANG weight'] * betas.iloc[4] +\n",
    "    portfolios['MRO weight'] * betas.iloc[5] +\n",
    "    portfolios['OVV weight'] * betas.iloc[6] +\n",
    "    portfolios['OXY weight'] * betas.iloc[7] +\n",
    "    portfolios['PXD weight'] * betas.iloc[8] +\n",
    "    portfolios['RF weight'] * betas.iloc[9] +\n",
    "    portfolios['XOM weight'] * betas.iloc[-1])* (MKT - ind_er.iloc[-2])\n",
    "\n",
    "portfolios.sort_values(by=['Sharpe'], ascending = False)\n",
    "# Dataframe of the 10000 portfolios created\n",
    "# the first one provides the highest Sharpe Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the efficient frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the efficient frontier\n",
    "portfolios.plot.scatter(x='Volatility', y='Returns', marker='o', s=10, alpha=0.3, grid=True, figsize=[10,10])\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-5, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Rankings for these methodology\n",
    "portfolios['Vol_rank'] = portfolios['Volatility'].rank(method='min')\n",
    "portfolios['Sharpe_rank'] = portfolios['Sharpe'].rank(ascending=False)\n",
    "portfolios['Trey_rank'] = portfolios['Treynor'].rank(ascending=False)\n",
    "portfolios['Jensen_rank'] = portfolios['Jensen'].rank(ascending=False)\n",
    "portfolios['Highest_rank'] = portfolios['Jensen_rank'] + portfolios['Trey_rank'] + portfolios['Sharpe_rank'] + portfolios['Vol_rank']\n",
    "portfolios.sort_values(by=['Highest_rank'], ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum Return Portofolio\n",
    "max_ret_port = portfolios.iloc[portfolios['Returns'].idxmax()]\n",
    "# idxmax() gives us the maximum value in the column specified.                               \n",
    "max_ret_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum Volatility Portofolio\n",
    "min_vol_port = portfolios.iloc[portfolios['Volatility'].idxmin()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "min_vol_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest Sharpe Ratio Portofolio\n",
    "max_sharpe_port = portfolios.iloc[portfolios['Sharpe'].idxmax()]\n",
    "max_sharpe_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest Treynor Ratio Portofolio\n",
    "max_tre_port = portfolios.iloc[portfolios['Treynor'].idxmax()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "max_tre_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest Jensen's alpha Portofolio\n",
    "max_jen_port = portfolios.iloc[portfolios['Jensen'].idxmax()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "max_jen_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest overall rank\n",
    "high_all_port = portfolios.iloc[portfolios['Highest_rank'].idxmin()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "high_all_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview and Comparison\n",
    "Overview = pd.concat([min_vol_port, max_sharpe_port, max_tre_port, max_jen_port, high_all_port ], axis=1)\n",
    "#Overview.iloc[-2].rename('new_name', inplace=True)\n",
    "Overview.rename(columns={Overview.columns[0]: \"Min Volatility\"}, inplace=True)\n",
    "Overview.rename(columns={Overview.columns[1]: \"Max Sharpe\"}, inplace=True)\n",
    "Overview.rename(columns={Overview.columns[2]: \"Max Treynor\"}, inplace=True)\n",
    "Overview.rename(columns={Overview.columns[3]: \"Max Jensen Alpha\"}, inplace=True)\n",
    "Overview.rename(columns={Overview.columns[4]: \"High in overall methods\"}, inplace=True)\n",
    "Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Portfolio prediction testing\n",
    "\n",
    "Now that the portfolios arebuilt, they are left to be tested. \n",
    "\n",
    "The test period is chosen starting from March 2015 to March 2018. \n",
    "\n",
    "The portfolios were built with optimization regarding one specific ratio or index, namely,\n",
    "- Min Volatility\n",
    "- Max Sharpe Ratio\n",
    "- Max Treynor Ratio\n",
    "- Max Jensn Alpha\n",
    "- Max overall Score\n",
    "\n",
    "By comparing the daily return using the weights in each portfolio, we are able to obverve Max Jensen portfolio has a much better return than other portfolios. Yet, such high return is brought with high risks, as what we have seen above in the corresponding volatilities of each portfolio. \n",
    "These portfolios are optimized based on the index or ratio they were built, so there is no easy answer which one is significantly better than the other. The investor has to choose based on their risk acceptances. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust of the original data\n",
    "Oil_df_final=Oil_df_final[[\"TICKER\", \"PRC\",\"date\"]]\n",
    "oil_table = Oil_df_final.pivot_table(index='date', columns='TICKER', values='PRC', aggfunc='sum').sort_values('date', ascending=True)\n",
    "oil_table = oil_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_date(start,end):\n",
    "    return start, end\n",
    "backtest_date = backtest_date(20150301,20180301)\n",
    "\n",
    "oil_table_bt = oil_table[(oil_table['date'] >= backtest_date[0]) & (oil_table['date'] <= backtest_date[1])]\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of Min Volatility Portofolio. \n",
    "oil_table_bt['Min_Volatility_PRC'] = (\n",
    "    100*(oil_table_bt['CLR']/oil_table_bt['CLR'].shift(1)-1) * min_vol_port.iloc[2] +\n",
    "    100*(oil_table_bt['COP']/oil_table_bt['COP'].shift(1)-1) * min_vol_port.iloc[3] +\n",
    "    100*(oil_table_bt['CVX']/oil_table_bt['CVX'].shift(1)-1) * min_vol_port.iloc[4] +\n",
    "    100*(oil_table_bt['EOG']/oil_table_bt['EOG'].shift(1)-1) * min_vol_port.iloc[5] +\n",
    "    100*(oil_table_bt['FANG']/oil_table_bt['FANG'].shift(1)-1) * min_vol_port.iloc[6] +\n",
    "    100*(oil_table_bt['MRO']/oil_table_bt['MRO'].shift(1)-1) * min_vol_port.iloc[7] +\n",
    "    100*(oil_table_bt['OVV']/oil_table_bt['OVV'].shift(1)-1) * min_vol_port.iloc[8] +\n",
    "    100*(oil_table_bt['OXY']/oil_table_bt['OXY'].shift(1)-1) * min_vol_port.iloc[9] +\n",
    "    100*(oil_table_bt['PXD']/oil_table_bt['PXD'].shift(1)-1) * min_vol_port.iloc[10] +\n",
    "    100*(oil_table_bt['RF']/oil_table_bt['RF'].shift(1)-1) * min_vol_port.iloc[11] +\n",
    "    100*(oil_table_bt['XOM']/oil_table_bt['XOM'].shift(1)-1) * min_vol_port.iloc[12])\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of Max Sharpe Portofolio\n",
    "oil_table_bt['Max_Sharpe_PRC'] = (\n",
    "    100*(oil_table_bt['CLR']/oil_table_bt['CLR'].shift(1)-1) * max_sharpe_port.iloc[2] +\n",
    "    100*(oil_table_bt['COP']/oil_table_bt['COP'].shift(1)-1) * max_sharpe_port.iloc[3] +\n",
    "    100*(oil_table_bt['CVX']/oil_table_bt['CVX'].shift(1)-1) * max_sharpe_port.iloc[4] +\n",
    "    100*(oil_table_bt['EOG']/oil_table_bt['EOG'].shift(1)-1) * max_sharpe_port.iloc[5] +\n",
    "    100*(oil_table_bt['FANG']/oil_table_bt['FANG'].shift(1)-1) * max_sharpe_port.iloc[6] +\n",
    "    100*(oil_table_bt['MRO']/oil_table_bt['MRO'].shift(1)-1) * max_sharpe_port.iloc[7] +\n",
    "    100*(oil_table_bt['OVV']/oil_table_bt['OVV'].shift(1)-1) * max_sharpe_port.iloc[8] +\n",
    "    100*(oil_table_bt['OXY']/oil_table_bt['OXY'].shift(1)-1) * max_sharpe_port.iloc[9] +\n",
    "    100*(oil_table_bt['PXD']/oil_table_bt['PXD'].shift(1)-1) * max_sharpe_port.iloc[10] +\n",
    "    100*(oil_table_bt['RF']/oil_table_bt['RF'].shift(1)-1) * max_sharpe_port.iloc[11] +\n",
    "    100*(oil_table_bt['XOM']/oil_table_bt['XOM'].shift(1)-1) * max_sharpe_port.iloc[12])\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of Max Treynor\tPortofolio\n",
    "oil_table_bt['Max_Treynor_PRC'] = (\n",
    "    100*(oil_table_bt['CLR']/oil_table_bt['CLR'].shift(1)-1) * max_tre_port.iloc[2] +\n",
    "    100*(oil_table_bt['COP']/oil_table_bt['COP'].shift(1)-1) * max_tre_port.iloc[3] +\n",
    "    100*(oil_table_bt['CVX']/oil_table_bt['CVX'].shift(1)-1) * max_tre_port.iloc[4] +\n",
    "    100*(oil_table_bt['EOG']/oil_table_bt['EOG'].shift(1)-1) * max_tre_port.iloc[5] +\n",
    "    100*(oil_table_bt['FANG']/oil_table_bt['FANG'].shift(1)-1) * max_tre_port.iloc[6] +\n",
    "    100*(oil_table_bt['MRO']/oil_table_bt['MRO'].shift(1)-1) * max_tre_port.iloc[7] +\n",
    "    100*(oil_table_bt['OVV']/oil_table_bt['OVV'].shift(1)-1) * max_tre_port.iloc[8] +\n",
    "    100*(oil_table_bt['OXY']/oil_table_bt['OXY'].shift(1)-1) * max_tre_port.iloc[9] +\n",
    "    100*(oil_table_bt['PXD']/oil_table_bt['PXD'].shift(1)-1) * max_tre_port.iloc[10] +\n",
    "    100*(oil_table_bt['RF']/oil_table_bt['RF'].shift(1)-1) * max_tre_port.iloc[11] +\n",
    "    100*(oil_table_bt['XOM']/oil_table_bt['XOM'].shift(1)-1) * max_tre_port.iloc[12])\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of Max Jensen Alpha Portofolio\n",
    "oil_table_bt['Max_Jensen_PRC'] = (\n",
    "    100*(oil_table_bt['CLR']/oil_table_bt['CLR'].shift(1)-1) * max_jen_port.iloc[2] +\n",
    "    100*(oil_table_bt['COP']/oil_table_bt['COP'].shift(1)-1) * max_jen_port.iloc[3] +\n",
    "    100*(oil_table_bt['CVX']/oil_table_bt['CVX'].shift(1)-1) * max_jen_port.iloc[4] +\n",
    "    100*(oil_table_bt['EOG']/oil_table_bt['EOG'].shift(1)-1) * max_jen_port.iloc[5] +\n",
    "    100*(oil_table_bt['FANG']/oil_table_bt['FANG'].shift(1)-1) * max_jen_port.iloc[6] +\n",
    "    100*(oil_table_bt['MRO']/oil_table_bt['MRO'].shift(1)-1) * max_jen_port.iloc[7] +\n",
    "    100*(oil_table_bt['OVV']/oil_table_bt['OVV'].shift(1)-1) * max_jen_port.iloc[8] +\n",
    "    100*(oil_table_bt['OXY']/oil_table_bt['OXY'].shift(1)-1) * max_jen_port.iloc[9] +\n",
    "    100*(oil_table_bt['PXD']/oil_table_bt['PXD'].shift(1)-1) * max_jen_port.iloc[10] +\n",
    "    100*(oil_table_bt['RF']/oil_table_bt['RF'].shift(1)-1) * max_jen_port.iloc[11] +\n",
    "    100*(oil_table_bt['XOM']/oil_table_bt['XOM'].shift(1)-1) * max_jen_port.iloc[12])\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of High in overall methods Portofolio\n",
    "oil_table_bt['High_overall_PRC'] = (\n",
    "    100*(oil_table_bt['CLR']/oil_table_bt['CLR'].shift(1)-1) * high_all_port.iloc[2] +\n",
    "    100*(oil_table_bt['COP']/oil_table_bt['COP'].shift(1)-1) * high_all_port.iloc[3] +\n",
    "    100*(oil_table_bt['CVX']/oil_table_bt['CVX'].shift(1)-1) * high_all_port.iloc[4] +\n",
    "    100*(oil_table_bt['EOG']/oil_table_bt['EOG'].shift(1)-1) * high_all_port.iloc[5] +\n",
    "    100*(oil_table_bt['FANG']/oil_table_bt['FANG'].shift(1)-1) * high_all_port.iloc[6] +\n",
    "    100*(oil_table_bt['MRO']/oil_table_bt['MRO'].shift(1)-1) * high_all_port.iloc[7] +\n",
    "    100*(oil_table_bt['OVV']/oil_table_bt['OVV'].shift(1)-1) * high_all_port.iloc[8] +\n",
    "    100*(oil_table_bt['OXY']/oil_table_bt['OXY'].shift(1)-1) * high_all_port.iloc[9] +\n",
    "    100*(oil_table_bt['PXD']/oil_table_bt['PXD'].shift(1)-1) * high_all_port.iloc[10] +\n",
    "    100*(oil_table_bt['RF']/oil_table_bt['RF'].shift(1)-1) * high_all_port.iloc[11] +\n",
    "    100*(oil_table_bt['XOM']/oil_table_bt['XOM'].shift(1)-1) * high_all_port.iloc[12])\n",
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_table_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the comparsion\n",
    "oil_table_bt['date'] = pd.to_datetime(oil_table_bt['date'], format='%Y%m%d') #change the date types\n",
    "oil_table_bt.index = oil_table_bt['date']\n",
    "# Resample the data by year\n",
    "oil_table_bt = oil_table_bt.resample('3M').mean()\n",
    "\n",
    "oil_table_bt = oil_table_bt.reset_index()\n",
    "# create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "# plot each column as a separate line\n",
    "oil_table_bt.plot(x='date', y='Min_Volatility_PRC', ax=ax, label='Min Volatility')\n",
    "oil_table_bt.plot(x='date', y='Max_Sharpe_PRC', ax=ax, label='Max Sharpe')\n",
    "oil_table_bt.plot(x='date', y='Max_Treynor_PRC', ax=ax, label='Max Treynor')\n",
    "oil_table_bt.plot(x='date', y='Max_Jensen_PRC', ax=ax, label='Max Jensen')\n",
    "oil_table_bt.plot(x='date', y='High_overall_PRC', ax=ax, label='High Overall')\n",
    "\n",
    "# add a legend\n",
    "ax.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37355852303588ca50c0d90cd3aeea3569d840c4b72ea65205330862f186e32f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
